{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d73bb85a",
   "metadata": {},
   "source": [
    "## Python Chatbot using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab947ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Greetings!\n",
      "Chatbot: I'm here to help you with your questions.\n",
      "Chatbot: No problem!\n",
      "Chatbot: Goodbye!\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "intents = {\n",
    "    \"greeting\": {\n",
    "        \"patterns\": [\"Hi\", \"Hello\", \"Hey\", \"Good morning\", \"Good evening\"],\n",
    "        \"responses\": [\"Hello!\", \"Hi there!\", \"Greetings!\"]\n",
    "    },\n",
    "    \"goodbye\": {\n",
    "        \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\"],\n",
    "        \"responses\": [\"Goodbye!\", \"See you later!\", \"Take care!\"]\n",
    "    },\n",
    "    \"thanks\": {\n",
    "        \"patterns\": [\"Thanks\", \"Thank you\", \"Much appreciated\"],\n",
    "        \"responses\": [\"You're welcome!\", \"No problem!\", \"Anytime!\"]\n",
    "    },\n",
    "    \"about\": {\n",
    "        \"patterns\": [\"What is this?\", \"Tell me about yourself\", \"Who are you?\"],\n",
    "        \"responses\": [\"I am a chatbot created to assist you.\", \"I'm here to help you with your questions.\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# text preprocessing function\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "# Prepare training data\n",
    "X = []\n",
    "\n",
    "y = []\n",
    "\n",
    "for intent, data in intents.items():\n",
    "    for pattern in data['patterns']:\n",
    "        X.append(preprocess_text(pattern))\n",
    "        y.append(intent)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectors = vectorizer.fit_transform(X)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_vectors, y)\n",
    "\n",
    "# chatbot response function\n",
    "def get_chatbot_response(user_input):\n",
    "    processed_input = preprocess_text(user_input)\n",
    "    input_vector = vectorizer.transform([processed_input])\n",
    "    predicted_intent = model.predict(input_vector)[0]\n",
    "    return random.choice(intents[predicted_intent]['responses'])\n",
    "\n",
    "# run the chatbot\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    response = get_chatbot_response(user_input)\n",
    "    print(f\"Chatbot: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5143a52b",
   "metadata": {},
   "source": [
    "## Text Classification using SNIPS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for SNIPS dataset\n",
    "# !pip install datasets transformers scikit-learn pandas numpy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================================================\n",
    "# Load SNIPS Dataset\n",
    "# ============================================================\n",
    "print(\"Loading SNIPS dataset...\")\n",
    "dataset = load_dataset(\"snips_built_in_intents\")\n",
    "\n",
    "# Display dataset information\n",
    "print(\"Dataset structure:\", dataset)\n",
    "print(\"\\nTrain dataset size:\", len(dataset['train']))\n",
    "print(\"Test dataset size:\", len(dataset['test']))\n",
    "print(\"\\nSample data:\")\n",
    "print(dataset['train'][0])\n",
    "\n",
    "# ============================================================\n",
    "# Data Preparation and Preprocessing\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Data Preparation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Convert dataset to pandas DataFrame for easier manipulation\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "\n",
    "print(\"Train DataFrame shape:\", train_df.shape)\n",
    "print(\"\\nLabel distribution in training data:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "# Get unique labels\n",
    "label_names = dataset['train'].features['label'].names\n",
    "print(\"\\nLabel names:\")\n",
    "for idx, name in enumerate(label_names):\n",
    "    print(f\"{idx}: {name}\")\n",
    "\n",
    "# Extract text and labels\n",
    "X_train = train_df['text'].tolist()\n",
    "y_train = train_df['label'].tolist()\n",
    "X_test = test_df['text'].tolist()\n",
    "y_test = test_df['label'].tolist()\n",
    "\n",
    "print(\"\\nTraining samples:\", len(X_train))\n",
    "print(\"Test samples:\", len(X_test))\n",
    "print(\"\\nExample texts:\")\n",
    "for i in range(3):\n",
    "    print(f\"{i+1}. Text: '{X_train[i]}' -> Label: {label_names[y_train[i]]}\")\n",
    "\n",
    "# ============================================================\n",
    "# Feature Extraction using TF-IDF\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Feature Extraction using TF-IDF\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=2)\n",
    "\n",
    "# Fit and transform training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF feature shape (train):\", X_train_tfidf.shape)\n",
    "print(\"TF-IDF feature shape (test):\", X_test_tfidf.shape)\n",
    "print(\"Vocabulary size:\", len(tfidf_vectorizer.vocabulary_))\n",
    "\n",
    "# ============================================================\n",
    "# Model Training - Logistic Regression\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Model Training - Logistic Regression\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (Logistic Regression):\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=label_names))\n",
    "\n",
    "# ============================================================\n",
    "# Model Training - Naive Bayes\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Model Training - Naive Bayes\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Train Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "nb_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"Naive Bayes Accuracy: {nb_accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (Naive Bayes):\")\n",
    "print(classification_report(y_test, y_pred_nb, target_names=label_names))\n",
    "\n",
    "# ============================================================\n",
    "# Model Training - Support Vector Machine (SVM)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Model Training - Support Vector Machine (SVM)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Train SVM model (linear kernel)\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (SVM):\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=label_names))\n",
    "\n",
    "# ============================================================\n",
    "# Model Comparison\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Model Comparison\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compare all models\n",
    "models_comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Naive Bayes', 'SVM'],\n",
    "    'Accuracy': [lr_accuracy, nb_accuracy, svm_accuracy]\n",
    "})\n",
    "\n",
    "models_comparison = models_comparison.sort_values('Accuracy', ascending=False)\n",
    "print(\"Model Comparison:\")\n",
    "print(models_comparison)\n",
    "\n",
    "# Visualize model comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models_comparison['Model'], models_comparison['Accuracy'], color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Comparison on SNIPS Dataset')\n",
    "plt.ylim([0, 1])\n",
    "for i, v in enumerate(models_comparison['Accuracy']):\n",
    "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# Confusion Matrix Visualization\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Confusion Matrix Visualization\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create confusion matrix for best model (usually Logistic Regression or SVM)\n",
    "cm = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=label_names, yticklabels=label_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# Testing with Custom Inputs\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Testing with Custom Inputs\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Function to predict intent for custom text\n",
    "def predict_intent(text, model=lr_model, vectorizer=tfidf_vectorizer):\n",
    "    \"\"\"\n",
    "    Predict the intent of a given text\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        model: Trained classification model\n",
    "        vectorizer: Fitted TF-IDF vectorizer\n",
    "    \n",
    "    Returns:\n",
    "        Predicted intent label and probability\n",
    "    \"\"\"\n",
    "    # Transform the input text\n",
    "    text_tfidf = vectorizer.transform([text])\n",
    "    \n",
    "    # Predict intent\n",
    "    predicted_label = model.predict(text_tfidf)[0]\n",
    "    predicted_intent = label_names[predicted_label]\n",
    "    \n",
    "    # Get prediction probabilities (if available)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probabilities = model.predict_proba(text_tfidf)[0]\n",
    "        confidence = probabilities[predicted_label]\n",
    "        return predicted_intent, confidence\n",
    "    else:\n",
    "        return predicted_intent, None\n",
    "\n",
    "# Test with custom inputs\n",
    "test_texts = [\n",
    "    \"Play some jazz music\",\n",
    "    \"What's the weather like today?\",\n",
    "    \"Book a table at an Italian restaurant\",\n",
    "    \"Add this song to my workout playlist\",\n",
    "    \"Find me a good action movie\",\n",
    "    \"I want to rate this book 5 stars\"\n",
    "]\n",
    "\n",
    "print(\"Custom Text Predictions:\")\n",
    "print(\"=\" * 80)\n",
    "for text in test_texts:\n",
    "    intent, confidence = predict_intent(text)\n",
    "    if confidence:\n",
    "        print(f\"Text: '{text}'\")\n",
    "        print(f\"Predicted Intent: {intent} (Confidence: {confidence:.4f})\")\n",
    "    else:\n",
    "        print(f\"Text: '{text}'\")\n",
    "        print(f\"Predicted Intent: {intent}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# ============================================================\n",
    "# Interactive Intent Classifier\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Interactive Intent Classifier\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Interactive loop for intent classification\n",
    "print(\"SNIPS Intent Classifier\")\n",
    "print(\"Available intents:\", \", \".join(label_names))\n",
    "print(\"Type 'quit' to exit\\n\")\n",
    "\n",
    "while True:\n",
    "    user_text = input(\"Enter your text: \")\n",
    "    \n",
    "    if user_text.lower() in ['quit', 'exit', 'q']:\n",
    "        print(\"Exiting intent classifier...\")\n",
    "        break\n",
    "    \n",
    "    if user_text.strip():\n",
    "        intent, confidence = predict_intent(user_text)\n",
    "        print(f\"âœ“ Predicted Intent: {intent}\")\n",
    "        if confidence:\n",
    "            print(f\"  Confidence: {confidence:.2%}\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
