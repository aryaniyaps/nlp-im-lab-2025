{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4bcdbb3",
   "metadata": {},
   "source": [
    "## Lab 3- Embeddings\n",
    "By Aryan Iyappan (2023115021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122b8c96",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d1a2cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  ['cat', 'fish', 'dog']\n",
      "One-hot encoded words: \n",
      "cat -> [1, 0, 0]\n",
      "dog -> [0, 0, 1]\n",
      "cat -> [1, 0, 0]\n",
      "fish -> [0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "words = [\"cat\", \"dog\", \"cat\", \"fish\"]\n",
    "\n",
    "vocab = list(set(words))\n",
    "\n",
    "one_hot = []\n",
    "\n",
    "for word in words:\n",
    "    vector = [1 if v == word else 0 for v in vocab]\n",
    "    one_hot.append(vector)\n",
    "\n",
    "print(\"Vocabulary: \", vocab)\n",
    "print(\"One-hot encoded words: \")\n",
    "for w, v in zip(words, one_hot):\n",
    "    print(w, \"->\", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1643c9e8",
   "metadata": {},
   "source": [
    "### One-hot encoding using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c083d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cat    dog   fish\n",
      "0   True  False  False\n",
      "1  False   True  False\n",
      "2  False  False   True\n",
      "3   True  False  False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.Series([\"cat\", \"dog\", \"fish\", \"cat\"])\n",
    "\n",
    "print(pd.get_dummies(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8b8e32",
   "metadata": {},
   "source": [
    "### One-hot encoding using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ca62505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories:  [array(['cat', 'dog', 'fish'], dtype='<U4')]\n",
      "One hot encoded output: \n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([[\"cat\"], [\"dog\"], [\"fish\"], [\"cat\"]])\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "encoded = encoder.fit_transform(data)\n",
    "\n",
    "print(\"Categories: \", encoder.categories_)\n",
    "\n",
    "print(\"One hot encoded output: \")\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfb2147",
   "metadata": {},
   "source": [
    "### Word2Vec implementation using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfddc67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for intelligence: \n",
      "[-0.01723938  0.00733148  0.01037977  0.01148388  0.01493384 -0.01233535\n",
      "  0.00221123  0.01209456 -0.0056801  -0.01234705 -0.00082045 -0.0167379\n",
      " -0.01120002  0.01420908  0.00670508  0.01445134  0.01360049  0.01506148\n",
      " -0.00757831 -0.00112361  0.00469675 -0.00903806  0.01677746 -0.01971633\n",
      "  0.01352928  0.00582883 -0.00986566  0.00879638 -0.00347915  0.01342277\n",
      "  0.0199297  -0.00872489 -0.00119868 -0.01139127  0.00770164  0.00557325\n",
      "  0.01378215  0.01220219  0.01907699  0.01854683  0.01579614 -0.01397901\n",
      " -0.01831173 -0.00071151 -0.00619968  0.01578863  0.01187715 -0.00309133\n",
      "  0.00302193  0.00358008]\n",
      "similar words to learning:  [('machine', 0.16704076528549194), ('deep', 0.13204392790794373), ('intelligence', 0.1267007291316986), ('part', 0.0998455286026001), ('is', 0.042373016476631165), ('powerful', 0.04067763686180115), ('neural', 0.012442179024219513), ('a', -0.01259106956422329), ('artificial', -0.01447527389973402), ('of', -0.0560765340924263)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [\n",
    "    \"artificial intelligence is powerful\".split(\" \"),\n",
    "    \"machine learning is a part of artificial intelligence\".split(\" \"),\n",
    "    \"deep learning uses neural networks\".split(\" \")\n",
    "]\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=50,\n",
    "    window=3,\n",
    "    min_count=1,\n",
    "    sg=1,\n",
    ")\n",
    "\n",
    "vector = model.wv[\"intelligence\"]\n",
    "\n",
    "print(\"Vector for intelligence: \")\n",
    "print(vector)\n",
    "\n",
    "similar_words = model.wv.most_similar(\"learning\")\n",
    "print(\"similar words to learning: \", similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc0114a",
   "metadata": {},
   "source": [
    "### GloVe implementation using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4fba397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
      "Vector for intelligence: \n",
      "[-0.31101   -0.43291    0.77734   -0.31115    0.052934  -0.8502\n",
      " -0.35372   -0.70531    0.084464   0.88768    0.83527   -0.41641\n",
      "  0.36703    0.60834    0.0085214  0.94293    0.5314    -0.75322\n",
      " -0.86764    0.34833   -0.29865   -0.43442    0.3514    -1.1228\n",
      " -1.2564    -0.094171   0.29402    0.31994    0.086692   0.31915\n",
      "  0.56067    0.032952  -0.94379   -0.58112    0.11274    0.006062\n",
      " -0.79353    0.70368    0.59687    0.60501   -0.22855   -0.26469\n",
      "  0.045172   0.58118    0.26756   -0.47237    0.29358   -0.28342\n",
      " -0.22823   -0.59532    1.0845     0.21541    0.5789     1.5825\n",
      "  0.15322   -1.3246     0.42594   -0.24834    1.3285     0.48737\n",
      "  0.17115    0.73042    0.51749   -0.50172    0.23246   -0.33179\n",
      " -0.31772    0.34714    0.95887    1.5972     0.76459   -0.1559\n",
      " -0.13554   -0.97654   -0.29545    0.097254  -0.17109    0.17695\n",
      " -1.1941     0.41086    1.0578     0.55551    0.034317  -0.18596\n",
      " -1.7366     0.22696    1.0213     0.80212   -0.017432  -0.45574\n",
      " -0.11358    0.032074  -0.37083    0.22161   -0.0030162  0.23286\n",
      "  0.16984   -1.0727    -0.18416    0.45819  ]\n",
      "teaching: 0.7720069289207458\n",
      "knowledge: 0.76064133644104\n",
      "experience: 0.7378624081611633\n",
      "skills: 0.734375\n",
      "learn: 0.7340658903121948\n",
      "understanding: 0.699902355670929\n",
      "education: 0.6989468336105347\n",
      "educational: 0.6864885687828064\n",
      "lessons: 0.681064784526825\n",
      "studying: 0.6762653589248657\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "glove_model = api.load(\"glove-wiki-gigaword-100\")\n",
    "\n",
    "vector = glove_model[\"intelligence\"]\n",
    "\n",
    "print(\"Vector for intelligence: \")\n",
    "print(vector)\n",
    "\n",
    "similar_words = glove_model.most_similar(\"learning\")\n",
    "for word, score in similar_words:\n",
    "    print(f\"{word}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da6dadc",
   "metadata": {},
   "source": [
    "### FastText embedding implmentation (using gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cb67e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for intelligence: \n",
      "[ 1.2442525e-03  6.1205524e-04 -7.8747980e-04  1.6670383e-04\n",
      " -2.2123381e-03 -1.2123872e-03 -1.2194589e-03 -3.8544473e-03\n",
      "  2.5588896e-03  1.5041081e-03  5.0475444e-03  1.2285195e-03\n",
      "  8.7324705e-04 -1.1611626e-04 -7.7292963e-04 -2.4581761e-03\n",
      " -1.2628294e-03 -1.8496130e-03  4.2046177e-05  2.7340525e-03\n",
      "  1.2192813e-03  1.2515471e-03  2.6138644e-03 -5.6116347e-04\n",
      "  1.2510451e-03  8.1061118e-04  2.9067504e-03  3.9396860e-04\n",
      " -5.7816796e-04 -2.8444370e-03  2.1801500e-03 -2.8956099e-04\n",
      " -2.9883529e-03 -3.0058046e-04 -7.7108195e-04  6.8529876e-04\n",
      " -1.3268661e-03  1.2676803e-03 -8.3737250e-04  9.6935441e-04\n",
      "  1.9220284e-03 -2.5679730e-03 -1.1573596e-03  1.0904556e-03\n",
      "  1.4968399e-03  1.2666686e-03  1.1835489e-03  7.3763513e-04\n",
      " -2.3163224e-04 -1.6384197e-03]\n",
      "processing: 0.2987723648548126\n",
      "extension: 0.23967039585113525\n",
      "embeddings: 0.2296343594789505\n",
      "an: 0.2120790332555771\n",
      "capture: 0.2046079933643341\n",
      "language: 0.18014957010746002\n",
      "fascinating: 0.1578020453453064\n",
      "meaning: 0.1501166671514511\n",
      "word: 0.11600217968225479\n",
      "natural: 0.10092004388570786\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "sentences = [\n",
    "    \"natural language processing is a fascinating field\".split(\" \"),\n",
    "    \"word embeddings capture semantic meaning\".split(\" \"),\n",
    "    \"fasttext is an extension of word2vec\".split(\" \")\n",
    "]\n",
    "\n",
    "model = FastText(\n",
    "    sentences,\n",
    "    vector_size=50,\n",
    "    window=3,\n",
    "    min_count=1,\n",
    "    sg=1,\n",
    ")\n",
    "\n",
    "vector = model.wv[\"intelligence\"]\n",
    "print(\"Vector for intelligence: \")\n",
    "print(vector)\n",
    "\n",
    "similar_words = model.wv.most_similar(\"learning\")\n",
    "for word, score in similar_words:\n",
    "    print(f\"{word}: {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
